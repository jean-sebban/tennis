---
title: "Projet de Data Science"
author: "Guillaume Allard, Jean Sebban et Fally Sow"
format: revealjs
editor: visual
---

# Problématique

::: incremental
1.  Construire un modèle permettant de prédire le résultat d'un match de tennis en simple, à partir d'informations sur les 2 joueurs qui s'affrontent et sur le tournoi.

2.  Classification supervisée : prédire Y (0 ou 1), à partir de variables explicatives quantitatives et qualitatives.
:::

## Sommaire

::: incremental
1.  Constitution de la base des matches

2.  Exploration de la base

3.  Calibrage des paramètres des modèles

4.  Comparaisons des performances des modèles

5.  Généralisation du modèle
:::

# 1 - Constitution de la base des matches

## Importation des fichiers

```{r,eval=FALSE}
match_stats_2017 <- read.csv2("data/match_stats_2017_unindexed_csv.csv",sep = ",")
match_stats_1991_2016 <- read.csv2("data/match_stats_1991-2016_unindexed_csv.csv",sep = ",")
joueurs <- read.csv2("data/player_overviews_unindexed_csv.csv",sep = ",")
tournois <- read.csv2("data/tournaments_1877-2017_unindexed_csv.csv",sep = ",")
match_scores_1991_2016 <- read.csv2("data/match_scores_1991-2016_unindexed_csv.csv",sep = ",")
match_scores_2017 <- read.csv2("data/match_scores_2017_unindexed_csv.csv",sep = ",")
classements_1973_2017 <- read.csv2("data/rankings_1973-2017_csv.csv",sep = ",")
```

Les fichiers source ont été récupérés sur le site [datahub](https://datahub.io/sports-data/atp-world-tour-tennis-data) :

-   **Matches :** stats et scores de 1991 à 2017 (n = 95 610)
-   **Joueurs :** (n = 10 912)
-   **Classements** (n = 2 694 539)
-   **Tournois** (n = 4 114)

## Calcul des stats sur les précédents matches

Stats calculées sur les 5 précédents matches, pour chaque joueur (winner et loser) :

::: incremental
-   Nombre de matches gagnés

-   Pourcentage d'aces

-   Pourcentage de double fautes

-   Pourcentage de premier service

-   Pourcentage de points gagnés au premier service

-   Pourcentage de points gagnés au deuxième service
:::

## Enrichissement de la base des matches

::: incremental
-   A partir de la base des **joueurs** (taille, poids et âge)

-   A partir de la base des **tournois** :

    -   surface (terre battue, gazon, dur, moquette)

    -   conditions (intérieur ou extérieur)

-   A partir de la base des **classements** (classements au moment du match + diff de classement)

-   Le fichier est constitué de 23 variables explicatives (dont 20 associées aux 2 joueurs)
:::

## Preprocessing avant modélisation

::: incremental
A partir du fichier avec les **95 610 matches** et **23 variables explicatives** :

-   Ajout de la variable target : **Y = 1**

-   Duplication de la base : **n = 191 220 matches**

-   Traitement des valeurs manquantes : **n = 158 870**

-   Nettoyage final (mise en forme, traitement anomalies) : **n = 149 852**
:::

# 2 - Exploration de la base

```{r}
library(skimr)
library(dplyr)
```

## Statistiques descriptives univariées

```{r}
don <- readRDS("./data/don_sansNA.rds") %>% 
  select(-starts_with("match"))
```

```{r,echo=TRUE}
summary(don)
```

# Méthode factorielle : ACP

## ACP : inertie expliquée par les axes

```{r}
library(FactoMineR)
set.seed(1234)
don_PCA <- dplyr::sample_n(don, 1000)[,-c(22,23)]
# don_PCA <- don[,-c(22,23)]
res.pca <- PCA(don_PCA,quali.sup = 1,quanti.sup = 22,graph = FALSE)
```

```{r, eval=FALSE, echo=TRUE}
res.pca <- PCA(don_PCA,quali.sup = 1,quanti.sup = 22)
barplot(res.pca$eig[,2])
```

```{r,echo=FALSE}
barplot(res.pca$eig[,2],names.arg = paste("",1:nrow(res.pca$eig)))
```

## ACP : graphe des variables

```{r,echo=TRUE}
plot(res.pca,choix = "var")
```

## ACP : description des axes

```{r,echo=TRUE}
dimdesc(res.pca)
```

# Clustering : méthode des K-means

## Premier clustering

```{r, eval=FALSE,echo=TRUE}
res.kmeans1 <- kmeans(don_kmeans_1,centers=4,nstart=50)
```

```{r}
don_kmeans <- don[,2:23]
# Selection des variables pour la Kmeans 
don_kmeans_1 <- don_kmeans[,c(4,5,6,7,8,9,10)]
dctrl_1 = don_kmeans[,c(4,5, 6, 7, 8, 9, 10)]

# Standardisation des données 
don_kmeans_1 <- scale(don_kmeans_1)


# On retient 4 groupes 
res.kmeans1 <- readRDS("data/clustering/res.kmeans1.RDS")

#boxplot(don$target~tmp$cluster)

Caract_group <- 
  dctrl_1 %>% 
  group_by(res.kmeans1$cluster) %>% 
  summarise_all(mean)

t(Caract_group)
```

## Deuxième clustering

```{r, eval=FALSE,echo=TRUE}
res.kmeans2 <- kmeans(don_kmeans_2,centers=4,nstart=50)
```

```{r}
# Selection des variables pour la Kmeans 
don_kmeans_2 <- don_kmeans[,c(1, 2, 3, 4, 8, 9, 10)]
dctrl_2 = don_kmeans[,c(1, 2, 3, 4, 8, 9, 10)]

# Standardisation des données 
don_kmeans_2 <- scale(don_kmeans_2)


# On retient 4 groupes 
res.kmeans2 <- readRDS("data/clustering/res.kmeans2.RDS")


#boxplot(don$target~tmp$cluster)

Caract_group <- 
  dctrl_2 %>% 
  group_by(res.kmeans2$cluster) %>% 
  summarise_all(mean)

t(Caract_group)
```

# 3 - Calibrage des paramètres des modèles

```{r}
library(glmnet)
library(gbm)
library(doParallel) #pour faire du multi coeur
```

```{r}
don <- readRDS("data/don_sansNA.rds")
```

## Séparation en fichier entraînement/test

```{r, echo=FALSE}

#fichier d'entraînement avec les matches de 1991 à 2014
don_train <- don %>% 
filter(!substr(match_stats_url_suffix,12,15) %in% c("2015","2016","2017")) %>% 
select(-match_stats_url_suffix)
```

```{r, echo=FALSE}
#fichier d'apprentissage contenant tous les matches de 1991 à 2012 
don_train_app <- don %>% 
  filter(!substr(match_stats_url_suffix,12,15) %in% c("2013","2014","2015","2016","2017")) %>% 
  select(-match_stats_url_suffix)

#fichier de validation sur les matches de 2013 et 2014
don_train_valid <- don  %>% 
  filter(substr(match_stats_url_suffix,12,15) %in% c("2013","2014")) %>% 
  select(-match_stats_url_suffix)


```

-   Entraînement (n = `r nrow(don_train)`) : matches de 1991 à 2014 :
    -   Apprentissage (n = `r nrow(don_train_app)`) : matches de 1991 à 2012
    -   Validation(n = `r nrow(don_train_valid)`) : matches de 2013 et 2014

```{r}
#fichier de test avec les matches de 2015 à 2017
don_test <- don %>% 
filter(substr(match_stats_url_suffix,12,15) %in% c("2015","2016","2017")) %>% 
select(-match_stats_url_suffix)
```

-   Test (n = `r nrow(don_test)`) : matches de 2015 à 2017.

# Modèles de regression logistique

## Algo 1 : regression logistique complète

```{r, echo=TRUE, eval=FALSE, include=TRUE}
 algo1 <- glm(target~.,data=don_train_app,family="binomial")
 summary(algo1)
```

```{r}
algo1 <- readRDS("data/algos/algo1.RDS")
summary(algo1)
```

## Algo 2 : logistique AIC

```{r, echo=TRUE, eval=FALSE}
algo2 <- step(algo1,trace=0)
summary(algo2)
```

```{r}
algo2 <- readRDS("data/algos/algo2.RDS")
summary(algo2)
```

## Algo 3 : logistique BIC

```{r, echo=TRUE, eval=FALSE}
 algo3 <- step(algo1,trace=0,k=log(nrow(don_train_app)))
 summary(algo3)
```

```{r}
algo3 <- readRDS("data/algos/algo3.RDS")
 summary(algo3)
```

# Arbres et forêts aléatoires

## Algo 4 : Arbre, choix de la profondeur

```{r}
library(rpart)
library(rpart.plot)
library(visNetwork)
```

```{r, echo=TRUE}
algo4 <- rpart(target~.,data=don_train_app,cp=0.0001,minsplit=5)
printcp(algo4)
```

## Algo 4 : Arbre optimisé

```{r}
algo4 <- rpart(target~.,data=don_train_app,cp=0.00032282,minsplit=5)
# rpart.plot(algo4,main="représentation de l'arbre")
visTree(algo4)
```

## Algo 5 : Forêt aléatoire

```{r}
library(randomForest)
```

```{r,echo=TRUE, eval=FALSE}
algo5 <- randomForest(target~.,data=don_train_app)
algo5
```

```{r}
algo5 <- readRDS("data/algos/algo5.RDS")
algo5
```

# Regression sous contrainte

```{r}
#Construction d'une version matrice pour glmnet : apprentissage
XXA <- model.matrix(target~.,data=don_train_app)   #version matrice
YYA <- don_train_app$target
```

## Algo 6 : Regression ridge

```{r,echo=TRUE, eval=FALSE}
algo6 <- cv.glmnet(XXA,YYA,alpha=0,family="binomial")
algo6$lambda.min
algo6$lambda.1se
```

```{r}
algo6 <- readRDS("data/algos/algo6.RDS")
algo6
```

## Algo 7 : Regression lasso

```{r,echo=TRUE, eval=FALSE}
algo7 <- cv.glmnet(XXA,YYA,alpha=1,family="binomial")
algo7$lambda.min
algo7$lambda.1se
```

```{r}
algo7 <- readRDS("data/algos/algo7.RDS")
algo7
```

## Algo 8 : Regression elastic net

```{r,echo=TRUE, eval=FALSE}
algo8 <- cv.glmnet(XXA,YYA,alpha=0.5,family="binomial")
algo8$lambda.min
algo8$lambda.1se
```

```{r}
algo8 <- readRDS("data/algos/algo8.RDS")
algo8
```

# Gradient-boosting

```{r}
don_train_app_gb <- don_train_app %>% mutate(target = as.numeric(target),
                                             target = case_when(
                                               target == 1 ~ 0,
                                               target == 2 ~ 1))
```

## Algo 9 : adaboost

```{r echo=TRUE, eval=FALSE}
algo9 <- gbm(target~.,data=don_train_app_gb,distribution = "adaboost",n.trees = 3000,shrinkage = 0.01,cv.folds = 5)
 mobt.ada <- gbm.perf(algo9,method = "cv")
 mobt.ada
```

```{r}
algo9 <- readRDS("data/algos/algo9.RDS")
mobt.ada <- gbm.perf(algo9,method = "cv")
mobt.ada
```

## Algo 10 : logit-boost

```{r, echo=TRUE, eval=FALSE}
algo10 <- gbm(target~.,data=don_train_app_gb,distribution = "bernoulli",n.trees = 3000,shrinkage = 0.05,cv.folds = 5)
mobt.logit <- gbm.perf(algo10,method = "cv")
mobt.logit
```

```{r}
algo10 <- readRDS("data/algos/algo10.RDS")
mobt.logit <- gbm.perf(algo10,method = "cv")
```

# 4 - Comparaisons des performances des modèles

## Calcul des probabilités

Calcul des probas sur le fichier de validation (matches de 2013 et 2014).

```{r, eval=FALSE}
#fichier de validation pour glmnet
XXT <- model.matrix(target~.,data=don_train_valid)

#fichier de validation pour gradient-boosting
don_train_valid_gb <- don_train_valid %>% mutate(target = as.numeric(target),
                                             target = case_when(
                                               target == 1 ~ 0,
                                               target == 2 ~ 1))

RES <- data.frame(Y=don_train_valid$target)
RES[,"log"] <- predict(algo1,don_train_valid,type="response")
RES[,"AIC"] <- predict(algo2,don_train_valid,type="response")
RES[,"BIC"] <- predict(algo3,don_train_valid,type="response")
RES[,"arbre"] <- predict(algo4,don_train_valid)[,2]
RES[,"foret"] <- predict(algo5,don_train_valid,type="prob")[,2]
RES[,"ridgemin"] <- predict(algo6,newx=XXT,s ="lambda.min",type="response") %>% as.numeric()
RES[,"ridge1se"] <- predict(algo6,newx=XXT,s ="lambda.1se",type="response") %>% as.numeric()
RES[,"lassomin"] <- predict(algo7,newx=XXT,s ="lambda.min",type="response") %>% as.numeric()
RES[,"lasso1se"] <- predict(algo7,newx=XXT,s ="lambda.1se",type="response") %>% as.numeric()
RES[,"elasmin"] <- predict(algo8,newx=XXT,s ="lambda.min",type="response") %>% as.numeric()
RES[,"elas1se"] <- predict(algo8,newx=XXT,s ="lambda.1se",type="response") %>% as.numeric()
RES[,"adaboost"] <-predict(algo9,newdata = don_train_valid_gb,type = "response",n.trees = mobt.ada)
RES[,"logitboost"] <-predict(algo10,newdata = don_train_valid_gb,type = "response",n.trees = mobt.logit)
saveRDS(RES,"data/RES_app_valid.RDS")
```

```{r}
RES <- readRDS("data/RES_app_valid.RDS")
set.seed(1237)
RES <- sample_n(RES,nrow(RES))
head(RES)
```

## Choix du seuil

Si la probabilité est supérieure à 50 %, alors le matche est gagné par le joueur 1 (Y = 1).

```{r}
RES2 <- RES

#Paramétrage du seuil
s <- 0.5
#boucle qui prend comme seuil 50%
for(ii in 2:ncol(RES2)){
  RES2[,ii] <- cut(RES2[,ii],breaks=c(-0.01,s,1.01),labels=c("0","1"))
}
head(RES2)
```

## Choix du critère

On choisit le **taux de bien classés** (accuracy) comme critère de performance du modèle.

```{r}
precis <- function(X,Y){sum(X==Y)/length(X)*100}
sort(apply(RES2,2,precis,Y=RES2$Y))
```

## Autres critères

```{r}
library(pROC)
library(purrr)
```

```{r}
auctoutlemonde <- roc(Y~.,data=RES)
res <- map_df(auctoutlemonde,coords,x=0.5,ret=c("accuracy","sensitivity",
                                                "specificity","recall"))
rownames(res) <- names(RES)[-1]
perf <- arrange(res,-accuracy)
perf
```

# 5 - Généralisation du modèle

## Définition du modèle final

```{r}
#Fichier d'apprentissage pour gradient boosting
don_train_gb <- don_train %>% mutate(target = as.numeric(target),
                                             target = case_when(
                                               target == 1 ~ 0,
                                               target == 2 ~ 1))
#   
# 
#fichier de test pour gradient boosting
don_test_gb <- don_test %>% mutate(target = as.numeric(target),
                                             target = case_when(
                                               target == 1 ~ 0,
                                               target == 2 ~ 1))
```

```{r, eval=FALSE, echo=TRUE}
algofinal <- gbm(target~.,data=don_train_gb,distribution = "bernoulli",
                 n.trees = 3000,shrinkage = 0.05,cv.folds = 5)
mobt.logit <- gbm.perf(algofinal,method = "cv")



```

```{r}
algofinal <- readRDS("data/algos/algofinal.RDS")
mobt.logit <- gbm.perf(algofinal,method = "cv")
mobt.logit
```

## Variables influentes

```{r}
summary(algofinal,graph=FALSE)[1:10,]
```

## Prévision sur le fichier test

```{r, echo=TRUE}
RES <- data.frame(Y=don_test$target)
RES[,"logitboost"] <-predict(algofinal,
                             newdata = don_test_gb,
                             type = "response",
                             n.trees = mobt.logit)
head(RES)

```

## Calcul de la performance

On prend un seuil à 50 % et on peut calculer le taux de mal classés (accuracy) sur le fichier test.

```{r}
RES2 <- RES
#Paramétrage du seuil
s <- 0.5
#boucle qui prend comme seuil 50%
for(ii in 2:ncol(RES2)){
  RES2[,ii] <- cut(RES2[,ii],breaks=c(-0.01,s,1.01),labels=c("0","1"))
}
precis <- function(X,Y){sum(X==Y)/length(X)*100}
sort(apply(RES2,2,precis,Y=RES2$Y))
```

![](images/IMG_6973-01.jpg)
