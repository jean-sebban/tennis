---
title: "Projet de Data Science"
author: "Jean Sebban, Fally et Guillaume Allard"
format: revealjs
editor: visual
---

# Problématique

1.  Construire un modèle permettant de prédire le résultat d'un match de tennis en simple, à partir d'informations sur les 2 joueurs qui s'affrontent et sur le tournoi.

2.  Classification supervisée : prédire Y (0 ou 1), à partir de variables explicatives quantitatives et qualitatives.

# Constitution de la base des matches

## Importation des fichiers

Les fichiers source ont été récupérés sur le site [datahub](https://datahub.io/sports-data/atp-world-tour-tennis-data) :

-   **Matches :** stats et scores de 1991 à 2017 (n = 95 610)
-   **Joueurs :** (n = 10 912)
-   **Classements** (n = 2 694 539)
-   **Tournois** (n = 4 114)

## Calcul des stats sur les précédents matches

Stats calculées sur les 5 précédents matches, pour chaque joueur (winner et loser) :

::: incremental
-   Nombre de matches gagnés

-   Pourcentage d'aces

-   Pourcentage de double fautes

-   Pourcentage de premier service

-   Pourcentage de points gagnés au premier service

-   Pourcentage de points gagnés au deuxième service
:::

## Enrichissement de la base des matches

::: incremental
-   A partir de la base des **joueurs** (taille, poids et âge)

-   A partir de la base des **tournois** :

    -   surface (terre battue, gazon, dur, moquette)

    -   conditions (intérieur ou extérieur)

-   A partir de la base des **classements** (classements au moment du match + diff de classement)
:::

Le fichier est constitué de 23 variables explicatives (dont 20 associées aux 2 joueurs)

## Preprocessing avant modélisation

::: incremental
-   Ajout de la variable target (**Y = 1**)

-   Duplication de la base : **n = 191 220 matches**

-   Traitement des valeurs manquantes (**n = 158 870**)

-   Nettoyage final (mise en factor, traitement anomalies) : **n = 149 852**
:::

# Exploration de la base

```{r}
library(skimr)
library(dplyr)
```

## Statistiques descriptives univariées

```{r}
don <- readRDS("./data/don_sansNA.rds") %>% 
  select(-starts_with("match")) %>% 
  filter(tourney_surface != "Carpet") #on enlève les matches sur moquette
```

```{r,echo=TRUE}

summary(don)
```

## ACP : inertie expliquée par les axes

```{r}
library(FactoMineR)
set.seed(1234)
res.pca <- PCA(sample_n(don, 1000)[,-c(22,23)],
               quali.sup = 1,
               quanti.sup = 22,
               graph = FALSE)
```

```{r,echo=TRUE}
barplot(res.pca$eig[,2],names.arg = paste("",1:nrow(res.pca$eig)))
```

## ACP : graphe des variables

```{r,echo=TRUE}
plot(res.pca,choix = "var")
```

## ACP : description des axes

```{r,echo=TRUE}
dimdesc(res.pca)
```

# Comparaison des modèles

```{r}
library(glmnet)
library(gbm)
library(doParallel) #pour faire du multi coeur
```

```{r}
don <- readRDS("data/don_sansNA.rds")
```

## Séparation en fichier entraînement/test

```{r, echo = TRUE}

#fichier d'entraînement avec les matches de 1991 à 2014
don_train <- don %>% 
filter(!substr(match_stats_url_suffix,12,15) %in% c("2015","2016","2017")) %>% 
select(-match_stats_url_suffix)
```

-   Le fichier d'entraînement (n = `r nrow(don_train)`) va permettre de sélectionner le modèle le plus performant avant de généraliser.

```{r}
#fichier de test avec les matches de 2015 à 2017
don_test <- don %>% 
filter(substr(match_stats_url_suffix,12,15) %in% c("2015","2016","2017")) %>% 
select(-match_stats_url_suffix)
```

-   Le fichier de test (n = `r nrow(don_test)`) sera utilisé pour généraliser le modèle.

## Validation hold out

On utilise ici une validation hold-out (apprentissage validation), pour tenir compte du caractère temporel des données.

```{r, echo=TRUE}
#fichier d'apprentissage contenant tous les matches de 1991 à 2012 
don_train_app <- don %>% 
  filter(!substr(match_stats_url_suffix,12,15) %in% c("2013","2014","2015","2016","2017")) %>% 
  select(-match_stats_url_suffix)

#fichier de validation sur les matches de 2013 et 2014
don_train_valid <- don  %>% 
  filter(substr(match_stats_url_suffix,12,15) %in% c("2013","2014")) %>% 
  select(-match_stats_url_suffix)


```

# Regression logistique

## Algo 1 : regression logistique complète

```{r, echo=TRUE}
 algo1 <- glm(target~.,data=don_train_app,family="binomial")
 summary(algo1)
```

## Algo 2 : logistique AIC

```{r, echo=TRUE}
algo2 <- step(algo1,trace=0)
summary(algo2)
```

## Algo 3 : logistique BIC

```{r, echo=TRUE}
 algo3 <- step(algo1,trace=0,k=log(nrow(don_train_app)))
 summary(algo3)
```

# Arbres et forêt aléatoire

## Algo 4 : arbre, choix de la profondeur

```{r}
library(rpart)
library(rpart.plot)
library(visNetwork)
```

```{r, echo=TRUE}
algo4 <- rpart(target~.,data=don_train_app,cp=0.0001,minsplit=5)
printcp(algo4)
```

## Algo4 Arbre : représentation

```{r}
algo4 <- rpart(target~.,data=don_train_app,cp=0.00026335,minsplit=5)
# rpart.plot(algo4,main="représentation de l'arbre")
visTree(algo4)
```

## Algo 5 : Forêt aléatoire

```{r}
library(randomForest)
```

```{r,echo=TRUE}
algo5 <- randomForest(target~.,data=don_train_app)
algo5
```

# Regression sous contrainte

```{r}
#Construction d'une version matrice pour glmnet : apprentissage
XXA <- model.matrix(target~.,data=don_train_app)   #version matrice
YYA <- don_train_app$target
```

## Algo 6 : Regression ridge

```{r,echo=TRUE}
algo6 <- cv.glmnet(XXA,YYA,alpha=0,family="binomial")
```

## Algo 7 : Regression lasso

```{r,echo=TRUE}
 algo7 <- cv.glmnet(XXA,YYA,alpha=1,family="binomial")
```

## Algo 8 : Regression elastic-net

```{r,echo=TRUE}
algo8 <- cv.glmnet(XXA,YYA,alpha=0.5,family="binomial")
```

# Gradient-boosting

# Généralisation du modèle
